{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klarh/geometric_algebra_attention/examples/Structure%20identification%20using%20jax.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Colab-specific setup that will be ignored elsewhere\n",
    "if [ ! -z \"$COLAB_GPU\" ]; then\n",
    "    pip install flowws-keras-geometry flowws-keras-experimental pyriodic-aflow freud-analysis\n",
    "    pip install git+https://github.com/klarh/geometric_algebra_attention\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More TPU and colab-specific setup\n",
    "import os\n",
    "if 'TPU_NAME' in os.environ:\n",
    "    import jax.tools.colab_tpu\n",
    "    jax.tools.colab_tpu.setup_tpu()\n",
    "\n",
    "import pyriodic\n",
    "for (n,) in pyriodic.db.query('select count(name) from unit_cells'):\n",
    "    if n == 0:\n",
    "        msg = \"\"\"The colab import machinery sometimes makes pyriodic not get\n",
    "        initialized correctly. Restarting the runtime should make it work properly.\"\"\"\n",
    "        raise RuntimeError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowws\n",
    "from flowws import Argument as Arg\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental.stax import serial, Dense, Relu\n",
    "\n",
    "from geometric_algebra_attention.jax import VectorAttention\n",
    "\n",
    "def make_layernorm():\n",
    "    def init(rng, input_shape):\n",
    "        return input_shape, ()\n",
    "\n",
    "    def eval_(params, x, rng=None):\n",
    "        return jax.nn.normalize(x)\n",
    "\n",
    "    return init, eval_\n",
    "\n",
    "@flowws.add_stage_arguments\n",
    "class CrystalStructureClassification(flowws.Stage):\n",
    "    \"\"\"Build a geometric attention network for the structure identification task.\n",
    "\n",
    "    This module specifies the architecture of a network to classify\n",
    "    local environments of crystal structures in a rotation-invariant\n",
    "    manner.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ARGS = [\n",
    "        Arg('rank', None, int, 2,\n",
    "            help='Degree of correlations (n-vectors) to consider'),\n",
    "        Arg('n_dim', '-n', int, 32,\n",
    "            help='Working dimensionality of point representations'),\n",
    "        Arg('dilation', None, float, 2,\n",
    "            help='Working dimension dilation factor for MLP components'),\n",
    "        Arg('merge_fun', '-m', str, 'mean',\n",
    "            help='Method to merge point representations'),\n",
    "        Arg('join_fun', '-j', str, 'mean',\n",
    "            help='Method to join invariant and point representations'),\n",
    "        Arg('n_blocks', '-b', int, 2,\n",
    "            help='Number of deep blocks to use'),\n",
    "        Arg('block_nonlinearity', None, bool, True,\n",
    "            help='If True, add a nonlinearity to the end of each block'),\n",
    "        Arg('residual', '-r', bool, True,\n",
    "            help='If True, use residual connections within blocks'),\n",
    "        Arg('invariant_mode', None, str, 'single',\n",
    "            help='Attention mechanism rotation-invariant attribute mode'),\n",
    "    ]\n",
    "\n",
    "    def run(self, scope, storage):\n",
    "        rank = self.arguments['rank']\n",
    "        n_dim = self.arguments['n_dim']\n",
    "        dilation_dim = int(np.round(n_dim*self.arguments['dilation']))\n",
    "        merge_fun = self.arguments['merge_fun']\n",
    "        join_fun = self.arguments['join_fun']\n",
    "        invar_mode = self.arguments['invariant_mode']\n",
    "\n",
    "        score = serial(\n",
    "            Dense(dilation_dim),\n",
    "            Relu,\n",
    "            Dense(1)\n",
    "            )\n",
    "\n",
    "        value = serial(\n",
    "            Dense(dilation_dim),\n",
    "            make_layernorm(),\n",
    "            Relu,\n",
    "            Dense(n_dim)\n",
    "            )\n",
    "\n",
    "        def make_attention(reduce=False):\n",
    "            attention = VectorAttention(\n",
    "                score, value, reduce=reduce, rank=rank, merge_fun=merge_fun,\n",
    "                join_fun=join_fun, invariant_mode=invar_mode).stax_functions\n",
    "            return attention\n",
    "\n",
    "        def init(rng, input_shape):\n",
    "            (r_shape, v_shape) = input_shape\n",
    "\n",
    "            def rngs_(rng):\n",
    "                while True:\n",
    "                    (next_rng, rng) = jax.random.split(rng)\n",
    "                    yield next_rng\n",
    "            rngs = rngs_(rng)\n",
    "\n",
    "            def param(layer, sh):\n",
    "              (last_shape, p) = layer[0](next(rngs), sh)\n",
    "              params.append(p)\n",
    "              return last_shape\n",
    "\n",
    "            params = []\n",
    "            last_shape = param(vscale, v_shape)\n",
    "            for i, att in enumerate(attentions):\n",
    "                last_shape = param(att, (r_shape, last_shape))\n",
    "                if self.arguments['block_nonlinearity']:\n",
    "                    last_shape = param(block_nonlins[i], last_shape[1])\n",
    "            last_shape = param(final_attention, (r_shape, last_shape))\n",
    "            last_shape = param(final_mlp, last_shape[1])\n",
    "\n",
    "            return last_shape, params\n",
    "\n",
    "        def eval_(params, x, rng=None):\n",
    "            pstack = list(reversed(params))\n",
    "\n",
    "            def run(layer, x):\n",
    "                return layer[1](pstack.pop(), x)\n",
    "\n",
    "            (r, v) = x\n",
    "            last = run(vscale, v)\n",
    "            for i, att in enumerate(attentions):\n",
    "                residual_in = last\n",
    "                last = run(att, (r, last))\n",
    "                if self.arguments['block_nonlinearity']:\n",
    "                    last = run(block_nonlins[i], last)\n",
    "                if self.arguments['residual']:\n",
    "                    last = residual_in + last\n",
    "            last = run(final_attention, (r, last))\n",
    "            last = run(final_mlp, last)\n",
    "            return last\n",
    "\n",
    "        vscale = Dense(n_dim)\n",
    "        attentions = [make_attention() for _ in range(self.arguments['n_blocks'])]\n",
    "        block_nonlins = []\n",
    "        if self.arguments['block_nonlinearity']:\n",
    "            block_nonlins = self.arguments['n_blocks']*[value]\n",
    "        final_attention = make_attention(True)\n",
    "        final_mlp = serial(\n",
    "            Dense(dilation_dim), Relu, Dense(scope['num_classes']))\n",
    "\n",
    "        scope['model_functions'] = init, eval_\n",
    "        scope['loss'] = 'sparse_categorical_crossentropy'\n",
    "        scope.setdefault('metrics', []).append('sparse_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import flowws\n",
    "from flowws import Argument as Arg\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.special import logsumexp\n",
    "import jax.experimental.optimizers as optimizers\n",
    "\n",
    "OPTIMIZERS = dict(\n",
    "    adam=optimizers.adam,\n",
    "    sgd=optimizers.sgd\n",
    ")\n",
    "\n",
    "OPTIMIZER_ARGS = dict(\n",
    "    adam=[.005],\n",
    "    sgd=[.001]\n",
    ")\n",
    "\n",
    "class Losses:\n",
    "    @staticmethod\n",
    "    def sparse_categorical_crossentropy(prediction, y):\n",
    "        logp = prediction - logsumexp(prediction, axis=-1, keepdims=True)\n",
    "        return -jnp.take_along_axis(logp, y[..., None], axis=-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def sparse_accuracy(prediction, y):\n",
    "        return jnp.argmax(prediction, axis=-1) == y\n",
    "\n",
    "@flowws.add_stage_arguments\n",
    "class Train(flowws.Stage):\n",
    "    \"\"\"Train a jax model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ARGS = [\n",
    "        Arg('optimizer', '-o', str, 'adam',\n",
    "           help='optimizer to use'),\n",
    "        Arg('epochs', '-e', int, 32,\n",
    "           help='Max number of epochs'),\n",
    "        Arg('batch_size', '-b', int, 256,\n",
    "           help='Batch size'),\n",
    "        Arg('validation_split', '-v', float, .3),\n",
    "        Arg('seed', '-s', int, 13),\n",
    "        Arg('verbose', None, bool, True,\n",
    "            help='If True, print the training progress'),\n",
    "    ]\n",
    "\n",
    "    def run(self, scope, storage):\n",
    "        x_train, y_train = scope['x_train'], scope['y_train']\n",
    "        init_fun, eval_fun = scope['model_functions']\n",
    "\n",
    "        validation_data = None\n",
    "        if 'validation_data' in scope:\n",
    "            validation_data = scope['validation_data']\n",
    "        elif self.arguments['validation_split']:\n",
    "            if isinstance(x_train, (list, tuple)):\n",
    "                N = int(len(x_train[0])*self.arguments['validation_split'])\n",
    "                splits = [np.split(piece, [N]) for piece in x_train]\n",
    "                x_val = [piece[0] for piece in splits]\n",
    "                x_train = [piece[1] for piece in splits]\n",
    "            else:\n",
    "                N = int(len(x_train)*self.arguments['validation_split'])\n",
    "                x_val, x_train = np.split(x_train, [N])\n",
    "            y_val, y_train = np.split(y_train, [N])\n",
    "            validation_data = (x_val, y_val)\n",
    "\n",
    "        opt = self.arguments['optimizer']\n",
    "        (opt_init, opt_update, opt_params) = OPTIMIZERS[opt](*OPTIMIZER_ARGS[opt])\n",
    "\n",
    "        if isinstance(x_train, (list, tuple)):\n",
    "            x_shape = [v.shape for v in x_train]\n",
    "        else:\n",
    "            x_shape = x_train.shape\n",
    "\n",
    "        params = init_fun(jax.random.PRNGKey(self.arguments['seed']), x_shape)[1]\n",
    "        opt_state = opt_init(params)\n",
    "\n",
    "        lossfun = getattr(Losses, scope['loss'])\n",
    "\n",
    "        def loss(params, batch):\n",
    "            (x, y) = batch\n",
    "            prediction = eval_fun(params, x)\n",
    "            return jnp.sum(jnp.mean(lossfun(prediction, y), axis=0))\n",
    "\n",
    "        metric_names = scope.get('metrics', [])\n",
    "        @jax.jit\n",
    "        def metrics(params, batch):\n",
    "            (x, y) = batch\n",
    "            prediction = eval_fun(params, x)\n",
    "            result = []\n",
    "            for name in metric_names:\n",
    "                result.append(jnp.mean(getattr(Losses, name)(prediction, y)))\n",
    "            return jnp.array(result)\n",
    "\n",
    "        @jax.jit\n",
    "        def step(step, opt_state, batch):\n",
    "            params = opt_params(opt_state)\n",
    "            value, grads = jax.value_and_grad(loss)(params, batch)\n",
    "            opt_state = opt_update(step, grads, opt_state)\n",
    "            return value, opt_state, metrics(params, batch)\n",
    "\n",
    "        @jax.jit\n",
    "        def predict(params, x):\n",
    "          return jax.nn.softmax(eval_fun(params, x))\n",
    "\n",
    "        @jax.jit\n",
    "        def evaluate_batch(params, batch):\n",
    "            loss_val = loss(params, batch)\n",
    "            metric_vals = metrics(params, batch)\n",
    "            return jnp.concatenate([jnp.array([loss_val]), metric_vals])\n",
    "\n",
    "        def evaluate(params, batches):\n",
    "            return np.mean([evaluate_batch(params, batch_) for batch_ in batches], axis=0)\n",
    "\n",
    "        def batchfun(xs, ys):\n",
    "            batches = []\n",
    "            N = len(xs[0]) if isinstance(xs, (list, tuple)) else len(xs)\n",
    "            for i in range(0, N, self.arguments['batch_size']):\n",
    "                batch = slice(i, i + self.arguments['batch_size'])\n",
    "                if isinstance(xs, (list, tuple)):\n",
    "                    x = [piece[batch] for piece in xs]\n",
    "                else:\n",
    "                    x = xs[batch]\n",
    "                y = ys[batch]\n",
    "                batches.append((x, y))\n",
    "            return batches\n",
    "        batches = batchfun(x_train, y_train)\n",
    "        val_evaluate = functools.partial(evaluate, batches=batchfun(*validation_data))\n",
    "\n",
    "        step_count = 0\n",
    "        rng = np.random.default_rng(self.arguments['seed'])\n",
    "        batch_indices = np.arange(len(batches))\n",
    "        epoch_losses = []\n",
    "        for epoch in range(self.arguments['epochs']):\n",
    "            rng.shuffle(batch_indices)\n",
    "            batch_losses = []\n",
    "            for batch_index in batch_indices:\n",
    "                (last_loss, opt_state, batch_metrics) = step(step_count, opt_state, batches[batch_index])\n",
    "                batch_losses.append([last_loss] + list(batch_metrics))\n",
    "                step_count += 1\n",
    "            epoch_losses.append(np.mean(batch_losses, axis=0))\n",
    "            if validation_data is not None and metric_names:\n",
    "                val_evaluation = val_evaluate(opt_params(opt_state))\n",
    "                epoch_losses[-1] = np.concatenate([epoch_losses[-1], val_evaluation])\n",
    "            print(epoch, epoch_losses[-1])\n",
    "            batch_losses.clear()\n",
    "\n",
    "        scope['model'] = functools.partial(predict, opt_params(opt_state))\n",
    "        scope['train_log'] = epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowws\n",
    "from flowws_keras_geometry.data import PyriodicDataset\n",
    "\n",
    "w = flowws.Workflow(\n",
    "    [\n",
    "        PyriodicDataset(\n",
    "            noise=[1e-3, 5e-2, 0.1],\n",
    "            structures=[\n",
    "                \"hP2-Mg\",\n",
    "                \"cI2-W\",\n",
    "                \"cF4-Cu\",\n",
    "                \"cF8-C\",\n",
    "                \"cF8-SZn\",\n",
    "                \"cP46-Si\",\n",
    "                \"cF136-Si\",\n",
    "                \"cP2-ClCs\",\n",
    "            ],\n",
    "            size=2048,\n",
    "            num_neighbors=12,\n",
    "            test_fraction=0.2,\n",
    "            seed=13,\n",
    "        ),\n",
    "        CrystalStructureClassification(),\n",
    "        Train(epochs=32, batch_size=8),\n",
    "    ]\n",
    ")\n",
    "\n",
    "scope = w.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "\n",
    "log = np.array(scope['train_log'])\n",
    "pp.plot(log[:, 0], label='Train')\n",
    "pp.plot(log[:, 2], label='Val')\n",
    "pp.xlabel('Epoch'); pp.ylabel('Loss')\n",
    "pp.legend()\n",
    "\n",
    "pp.figure()\n",
    "pp.plot(log[:, 1], label='Train')\n",
    "pp.plot(log[:, 3], label='Val')\n",
    "pp.xlabel('Epoch'); pp.ylabel('Accuracy')\n",
    "pp.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Structure identification using jax.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
